{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "\n",
    "# Prints out a set nicely\n",
    "# names is an optional list of the names for each of the (integer) items\n",
    "def settostr(s, names=None):\n",
    "    if names is None:\n",
    "        elems = [str(e) for e in s]\n",
    "    else:\n",
    "        elems = [names[e] for e in s]\n",
    "    return \"{\" + (\", \".join(elems)) + \"}\"\n",
    "\n",
    "# Loads data from a file\n",
    "def loaddata(filename):\n",
    "    with open(filename) as f:\n",
    "        nitems = int(f.readline())\n",
    "        names = [f.readline().strip() for i in range(nitems)]\n",
    "        nrows = int(f.readline())\n",
    "        data = [[int(s) for s in f.readline().split()] for i in range(nrows)]\n",
    "        f.close()\n",
    "        return names, data, nitems\n",
    "\n",
    "def learnrules(numitems, data, minsupport, minconfidence):\n",
    "    # Generate frequent itemsets using the Apriori algorithm\n",
    "    def apriori(data, minsupport):\n",
    "        itemsets = [frozenset([item]) for item in range(numitems)]\n",
    "        frequent_itemsets = []\n",
    "        while itemsets:\n",
    "            # Generate candidate itemsets\n",
    "            candidates = set()\n",
    "            for itemset in itemsets:\n",
    "                for item in range(itemset[-1] + 1, numitems):\n",
    "                    candidates.add(itemset | frozenset([item]))\n",
    "            # Count support for each candidate itemset\n",
    "            support_counts = {}\n",
    "            for transaction in data:\n",
    "                for candidate in candidates:\n",
    "                    if candidate.issubset(transaction):\n",
    "                        support_counts[candidate] = support_counts.get(candidate, 0) + 1\n",
    "            # Prune candidates based on minimum support\n",
    "            itemsets = []\n",
    "            for candidate, support in support_counts.items():\n",
    "                if support >= minsupport:\n",
    "                    itemsets.append(candidate)\n",
    "                    frequent_itemsets.append((candidate, support))\n",
    "            # Join itemsets for the next iteration\n",
    "            itemsets = list(chain(*[combinations(itemset, r + 2) for itemset in itemsets]))\n",
    "        return frequent_itemsets\n",
    "\n",
    "    # Generate association rules from frequent itemsets\n",
    "    def generate_rules(frequent_itemsets, minconfidence):\n",
    "        rules = []\n",
    "        for itemset, support in frequent_itemsets:\n",
    "            if len(itemset) >= 2:\n",
    "                for i in range(1, len(itemset)):\n",
    "                    for antecedent in combinations(itemset, i):\n",
    "                        antecedent = frozenset(antecedent)\n",
    "                        consequent = itemset - antecedent\n",
    "                        confidence = support / frequent_itemsets_dict[antecedent]\n",
    "                        if confidence >= minconfidence:\n",
    "                            rules.append((antecedent, consequent, support, confidence))\n",
    "        return sorted(rules, key=lambda x: x[3], reverse=True)\n",
    "\n",
    "    frequent_itemsets = apriori(data, minsupport)\n",
    "    frequent_itemsets_dict = {itemset: support for itemset, support in frequent_itemsets}\n",
    "    rules = generate_rules(frequent_itemsets, minconfidence)\n",
    "    return rules\n",
    "\n",
    "def writerules(rules, data, itemnames):\n",
    "    for antecedent, consequent, support, confidence in rules:\n",
    "        antecedent_str = settostr(antecedent, itemnames)\n",
    "        consequent_str = settostr(consequent, itemnames)\n",
    "        support_str = \"{:7.4f}\".format(support / len(data))\n",
    "        confidence_str = \"{:7.4f}\".format(confidence)\n",
    "        print(f\"{support_str} {confidence_str} {antecedent_str} => {consequent_str}\")\n",
    "\n",
    "def printruleset(datasetfilename, minsupport, minconfidence):\n",
    "    itemnames, data, numitems = loaddata(datasetfilename)\n",
    "    rules = learnrules(numitems, data, minsupport, minconfidence)\n",
    "    writerules(rules, data, itemnames)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
