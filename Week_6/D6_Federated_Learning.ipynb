{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcpw7CLUFrq9"
      },
      "source": [
        "***\n",
        "**Author:** Josiah Wallis \\\n",
        "Created for use in CS/STAT108: Data Science Ethics (UCR - Winter 2024)\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBNCayDEEGU3"
      },
      "source": [
        "# Federated Learning from the bottom up\n",
        "This week, we'll take a look at the difference between centralized and decentralized learning models. We'll also take a look at working with image data, a convolutional neural network, and how these elements come together to build a federated model. The goal of this discussion is not to understand every little aspect of the code, but to understand the bigger picture of what federated learning can do and how it preserves privacy. It's meant for exposure!\n",
        "\n",
        "This notebook is meant to be covered in discussion and will not be self-contained or easily understood if read without having attended discussion. I will update the text and information in the future so the notebook can be read without the discussion.\n",
        "\n",
        "## Note\n",
        "Please run this ipython notebook in an environment where you have access to TPUs or GPUs. If you are using google colab, navigate to **Edit**, **Notebook Settings**, select **T4 GPU** then **save**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yacU4CAFtG9"
      },
      "source": [
        "***\n",
        "# Centralized Model\n",
        "A **centralized model** can be considered a model that operates in a single computing unit like a computer. Models run on your own device are typically considered centralized models as the model itself, as well as the data, are located on a single device.\n",
        "\n",
        "In this section, we will be applying a convolutional neural network (CNN) to a classification problem: classifying handwritten images as numbers from 0 to 9.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cmbnOFEeMTLu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Peter\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import relevant libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For plotting barplots with bar count text\n",
        "def better_bar(cats, heights, color: str = 'blue', ylim: bool = 'True') -> None:\n",
        "  barplot = plt.bar(cats, heights, edgecolor = 'black', color = color)\n",
        "  plt.xticks(cats)\n",
        "  if ylim:\n",
        "    plt.ylim(0.95 * np.min(heights), 1.05 * np.max(heights))\n",
        "\n",
        "  for i, bar in enumerate(plt.bar(cats, heights)):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(heights[i]),\n",
        "             ha='center', va='bottom')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3_NM3cQHYrk"
      },
      "source": [
        "Load MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Qm1ZmQNfN7mT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample/Feature shape: (28, 28)\n",
            "Training Samples: 60000\n",
            "Testing Samples: 10000\n",
            "Train-Test Split: 86-14\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(f'Sample/Feature shape: {X_train.shape[1:]}')\n",
        "print(f'Training Samples: {X_train.shape[0]}')\n",
        "print(f'Testing Samples: {X_test.shape[0]}')\n",
        "\n",
        "total_samp = len(X_train) + len(X_test)\n",
        "print(f'Train-Test Split: {len(X_train) / total_samp * 100:.0f}-{len(X_test) / total_samp * 100:.0f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XySQQJQHeKh"
      },
      "source": [
        "Visualize some of our sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiNOENh-OZkA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10, 8))\n",
        "for i in range(25):\n",
        "  plt.subplot(5, 5, i + 1)\n",
        "  plt.imshow(X_train[i], cmap = 'gray')\n",
        "  plt.title(f'Label: {y_train[i]}')\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.suptitle('MNIST Training Samples')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4NWTVHeHnCK"
      },
      "source": [
        "Combine data to do visualize label distribution. Note we still have variables that stored the data when it was split. After this cell, we'll have\n",
        "* X_train, y_train - Training dataset (86% of total data)\n",
        "* X_test, y_test - Test dataset (14% of total data)\n",
        "* X, y - Whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTfXNejYZkxk"
      },
      "outputs": [],
      "source": [
        "X, y = np.concatenate([X_train, X_test]), np.concatenate([y_train, y_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8N6uXXddM_c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (16, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "better_bar(np.arange(10), np.unique(y, return_counts = True)[1])\n",
        "plt.title('Label Distribution')\n",
        "plt.xlabel('Labels')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "better_bar(np.arange(10), np.unique(y_train, return_counts = True)[1])\n",
        "plt.title('Training Distribution')\n",
        "plt.xlabel('Labels')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "better_bar(np.arange(10), np.unique(y_test, return_counts = True)[1])\n",
        "plt.title('Testing Distribution')\n",
        "plt.xlabel('Labels')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eByIrAP1IP8N"
      },
      "source": [
        "One-hot encode labels to prepare for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRNRiCnYfNmC"
      },
      "outputs": [],
      "source": [
        "ohe = OneHotEncoder()\n",
        "y_train_ohe = ohe.fit_transform(y_train.reshape(len(y_train), 1)).toarray()\n",
        "y_test_ohe = ohe.fit_transform(y_test.reshape(len(y_test), 1)).toarray()\n",
        "y_train[:5], y_train_ohe[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1UnxkLyIZOS"
      },
      "source": [
        "Import neural network library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_Pqu2UNhYVB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGIMWFwVIg8F"
      },
      "source": [
        "Create our model - a **convolutional neural network**. CNNs are computationally efficient for handling image and video data. After the network learns from the data, it will assign a vector of probabilities to a given datapoint. The index with the highest probability can be interpreted as the **predicted label**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL6_wkNpiU2e"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(4, (2, 2), activation = 'relu', input_shape = (28, 28, 1), kernel_regularizer = regularizers.l2(0.01)),\n",
        "    MaxPooling2D((3, 3)),\n",
        "    Flatten(),\n",
        "    Dense(10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNmUIpBrJSY1"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyAf9foEi-ZH"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "history = model.fit(X_train, y_train_ohe, epochs = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KghpIIVJaDv"
      },
      "source": [
        "Evaluate the model on data it's never seen before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSHO9apPjUMw"
      },
      "outputs": [],
      "source": [
        "test_error, test_acc = model.evaluate(X_test, y_test_ohe, verbose = 0)\n",
        "print(f'Test Error: {test_error}')\n",
        "print(f'Test Accuracy: {test_acc:.2%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfxT3QKfJetD"
      },
      "source": [
        "# Decentralized Model\n",
        "A **decentralized model** is one that is either distributed across multiple devices, or the data it learns from is distributed across multiple devices. A **federated learning model** consists of a **central server** and **clients**. The clients train centralized models locally then send their model parameters to the central server. The central server aggregates the model parameters then distributes them back to the local models to use as starting weights for training. The final central server model, the federated model, will hopefully have learned from all the local clients - having a greater understanding of the types of data one can encounter in this domain, providing greater predictive power overall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2yy2NzdrbeJ"
      },
      "outputs": [],
      "source": [
        "# Function for simulating client data split\n",
        "def federate_data(data: np.ndarray, labels: np.ndarray, clients: int, seed = None, test_size = 0) -> tuple[list, list]:\n",
        "  if seed:\n",
        "    np.random.seed(seed)\n",
        "\n",
        "  # Copy and shuffle data\n",
        "  X = data.copy()\n",
        "  y = labels.copy()\n",
        "  shuffle_idxs = np.random.permutation(X.shape[0])\n",
        "  X = X[shuffle_idxs]\n",
        "  y = y[shuffle_idxs]\n",
        "\n",
        "  # Generate test data only accessible by central server\n",
        "  if test_size:\n",
        "    test_idx = int(X.shape[0] * test_size)\n",
        "    X_test = X[:test_idx]\n",
        "    y_test = y[:test_idx]\n",
        "    X = X[test_idx:]\n",
        "    y = y[test_idx:]\n",
        "\n",
        "  # Generate indices of where to split data\n",
        "  idxs = np.arange(X.shape[0])\n",
        "  split_idxs = np.sort(np.random.choice(idxs, clients - 1, replace = False))\n",
        "  data_chunks = []\n",
        "  label_chunks = []\n",
        "\n",
        "  # Splits data up between indices\n",
        "  for i in range(clients):\n",
        "    if i == 0:\n",
        "      data_chunk = X[:split_idxs[0]]\n",
        "      label_chunk = y[:split_idxs[0]]\n",
        "    elif i == len(split_idxs):\n",
        "      data_chunk = X[split_idxs[-1]:]\n",
        "      label_chunk = y[split_idxs[-1]:]\n",
        "    else:\n",
        "      data_chunk = X[split_idxs[i - 1]: split_idxs[i]]\n",
        "      label_chunk = y[split_idxs[i - 1]: split_idxs[i]]\n",
        "\n",
        "    data_chunks.append(data_chunk)\n",
        "    label_chunks.append(label_chunk)\n",
        "\n",
        "  if test_size:\n",
        "    return data_chunks, label_chunks, (X_test, y_test)\n",
        "\n",
        "  return data_chunks, label_chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN87GdavKoTE"
      },
      "source": [
        "We can check how many samples each client has"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJfb6NZErBs4"
      },
      "outputs": [],
      "source": [
        "clients = 5\n",
        "y = OneHotEncoder().fit_transform(y.reshape(len(y), 1)).toarray()\n",
        "data_chunks, label_chunks, (X_test, y_test) = federate_data(X, y, clients, test_size = 0.15)\n",
        "\n",
        "counts = []\n",
        "for client in data_chunks:\n",
        "  counts.append(len(client))\n",
        "\n",
        "better_bar(np.arange(clients), counts)\n",
        "plt.title('Client Data Distribution')\n",
        "plt.xlabel('Clients')\n",
        "plt.ylabel('Samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DVfrEcyKrTF"
      },
      "source": [
        "Let's see the distribution of test labels we'll use to test our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH_AHOCoyA_s"
      },
      "outputs": [],
      "source": [
        "print(f'Testing Samples: {X_test.shape[0]}')\n",
        "better_bar(np.arange(10), np.unique(np.argmax(y_test, axis = 1), return_counts = True)[1])\n",
        "plt.title('Federated Testing Distribution')\n",
        "plt.xlabel('Labels')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTEXtar2K2pC"
      },
      "source": [
        "The `Client` class will act as a container for our distributed data. It will simulate a local/centralized model, like a company who will later share their model parameters with the central server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-uXCCVtyWNB"
      },
      "outputs": [],
      "source": [
        "class Client():\n",
        "  def __init__(self, data, labels, model = None):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "    self.recent_history = None\n",
        "\n",
        "    if not model:\n",
        "      self.model = Sequential([\n",
        "          Conv2D(4, (2, 2), activation = 'relu', input_shape = (28, 28, 1), kernel_regularizer = regularizers.l2(0.01)),\n",
        "          MaxPooling2D((3, 3)),\n",
        "          Flatten(),\n",
        "          Dense(10, activation = 'softmax')\n",
        "      ])\n",
        "    else:\n",
        "      self.model = model\n",
        "\n",
        "  def fit(self, epochs = 5):\n",
        "    self.model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    self.recent_history = self.model.fit(self.data, self.labels, epochs = epochs, verbose = 0)\n",
        "\n",
        "  def set_weights(self, weights):\n",
        "    return self.model.set_weights(weights)\n",
        "\n",
        "  def get_weights(self):\n",
        "    return self.model.get_weights()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I_MdKsFLG6-"
      },
      "source": [
        "Initialize the clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30BmkTNiz15a"
      },
      "outputs": [],
      "source": [
        "clients = []\n",
        "for data, labels in zip(data_chunks, label_chunks):\n",
        "  new_client = Client(data, labels)\n",
        "  clients.append(new_client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Six9Hpc8LNcV"
      },
      "source": [
        "Here is where we create the federated model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUAFkenP3x3h"
      },
      "outputs": [],
      "source": [
        "# Helper function - aggregates model parameters in a given round\n",
        "def aggregate(weights):\n",
        "  aggregated_weights = []\n",
        "\n",
        "  # Takes the average of parameters in model layer i\n",
        "  num_layers = len(weights[0])\n",
        "  for i in range(num_layers):\n",
        "    layer_weights = np.array([layer_weights[i] for layer_weights in weights])\n",
        "    layer_weights = np.mean(layer_weights, axis = 0)\n",
        "    aggregated_weights.append(layer_weights)\n",
        "\n",
        "  return aggregated_weights\n",
        "\n",
        "# Generates the federated model\n",
        "def federated_model(clients, training_rounds, X_test = None, y_test = None, model = None):\n",
        "  # Default architecture of our CNN\n",
        "  if not model:\n",
        "    global_model = Sequential([\n",
        "      Conv2D(4, (2, 2), activation = 'relu', input_shape = (28, 28, 1), kernel_regularizer = regularizers.l2(0.01)),\n",
        "      MaxPooling2D((3, 3)),\n",
        "      Flatten(),\n",
        "      Dense(10, activation = 'softmax')\n",
        "    ])\n",
        "  else:\n",
        "    global_model = model\n",
        "\n",
        "  # Give the model some default settings\n",
        "  global_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "  # Get the starting weights for the global model before any training takes place\n",
        "  curr_weights = global_model.get_weights()\n",
        "\n",
        "  # Store global model's performance after each round\n",
        "  test_accs = []\n",
        "\n",
        "  for t in range(training_rounds):\n",
        "\n",
        "    # Stores the parameters of each client for a given round\n",
        "    client_weights = []\n",
        "\n",
        "    for i, client in enumerate(clients):\n",
        "      # Distributes global model's parameters to local client\n",
        "      client.set_weights(curr_weights)\n",
        "\n",
        "      # Train local model on local data\n",
        "      client.fit()\n",
        "\n",
        "      # Client sends central server its weights\n",
        "      client_weight = client.get_weights()\n",
        "\n",
        "      # Store the weights for aggregation\n",
        "      client_weights.append(client_weight)\n",
        "\n",
        "    # Take the average of model parameters for each layer\n",
        "    curr_weights = aggregate(client_weights)\n",
        "\n",
        "    # Load the global model with the aggregated weights\n",
        "    global_model.set_weights(curr_weights)\n",
        "\n",
        "    print(f'Finished round {t + 1}')\n",
        "\n",
        "    if X_test is not None:\n",
        "      _, test_acc = global_model.evaluate(X_test, y_test, verbose = 0)\n",
        "      test_accs.append(test_acc)\n",
        "\n",
        "\n",
        "  return global_model, test_accs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aouy0cdjMsWO"
      },
      "source": [
        "How well did our global model do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6qa8i6Y48Zd"
      },
      "outputs": [],
      "source": [
        "global_model, test_accs = federated_model(clients, 3, X_test = X_test, y_test = y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uki0-jyD6FPn"
      },
      "outputs": [],
      "source": [
        "test_accs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
